# spark configs
spark: 
  enable_hive: false
  spark_conf:
    spark.executor.memory: "4g"
    spark.driver.memory: "2g"
    spark.sql.shuffle.partitions: "200"

# logging configs 
logging:
  log_dir: "output/logs"
  log_file: "application.log"
  level: "INFO"

# input data
input_data:
  primary_person_data: "data/raw/Primary_Person_use.csv"
  units_data: "data/raw//Units_use.csv"
  damages_data: "data/raw//Damages_use.csv"
  charges_data: "data/raw//Charges_use.csv"

# output data
output_data:
  analysis_1: "output/anaysis/analysis_1.csv"
  analysis_2: "output/anaysis/analysis_2.csv"
  analysis_3: "output/anaysis/analysis_3.csv"
  analysis_4: "output/anaysis/analysis_4.csv"
  analysis_5: "output/anaysis/analysis_5.csv"
  analysis_6: "output/anaysis/analysis_6.csv"
  analysis_7: "output/anaysis/analysis_7.csv"
  analysis_8: "output/anaysis/analysis_8.csv"
  analysis_9: "output/anaysis/analysis_9.csv"
  analysis_10: "output/anaysis/analysis_10.csv"


  logs: "output/logs/app.log"

# analysis to run
analyses_to_run:
  - src.analysis.analysis_1.Analysis1
  - src.analysis.analysis_2.Analysis2
  - src.analysis.analysis_3.Analysis3
  - src.analysis.analysis_4.Analysis4
  - src.analysis.analysis_5.Analysis5
  - src.analysis.analysis_6.Analysis6
  - src.analysis.analysis_7.Analysis7
  - src.analysis.analysis_8.Analysis8
  - src.analysis.analysis_9.Analysis9
  - src.analysis.analysis_10.Analysis10

